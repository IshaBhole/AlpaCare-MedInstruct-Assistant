{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08uBs8xBkt6p",
        "outputId": "14487ccf-cb12-4b99-db5f-0233a5d6fd87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
            "Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.48.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets peft accelerate bitsandbytes sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"lavita/AlpaCare-MedInstruct-52k\")\n",
        "\n",
        "# Check the dataset structure\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "876c992719644e338e11f3362cf6cb5e",
            "136c1561f1ac4f0789f934b9990b041e",
            "ae8950a7c2b545bb9a4e6d970385fc46",
            "26579a74417c47d397fc80d1073fab2c",
            "237c0643ed444bccb05f0cfbc5a61c2d",
            "add94cf2d91a49e28fd38685acf3f467",
            "64dd737a0c284309ba50e37e48661850",
            "ee4f96ada0ae416db0b0483afcf28647",
            "9b7e5e7a5b7649fc86736444462b9873",
            "187ebc59fa9e48ab996652fb949c2543",
            "37aaa4d470c84644875e6e73868094d1",
            "09cae9c3e9d14cf5a4420b226a21c394",
            "a65b307638634a90b0e00dfaf953fd36",
            "850fb1f5104949a286dd3becc96e405b",
            "c52c53b106f14e0aa6677e43caf321e1",
            "98dcfbeb835d40df8b27831b155d7bc3",
            "008faff0e2b842ffbe266c37a830e0fb",
            "19d5700836994249bee91677fd004961",
            "57464a6302634af39dad557b1f2e52d0",
            "0cd4f7057bdf48c88c9210d10d913647",
            "1bbc3fdb8cd54addb946e750c1eb1fca",
            "624173ada64943809bed866904d4ccfd",
            "2d03c09063d648f494c3c4f8ad0a16ed",
            "116e25102fac4c45a2a46f7b103fecf1",
            "4be5a1c1bd0c42b5b0e9b2bc414d23ac",
            "7768c696f8b045e38f5155ea2d5cdbf3",
            "50b09f60a8d642989b972a617e993a76",
            "8ca0f88711304877bd9fa7f378c42c9a",
            "861d5437fdae411ab5b12070d368cd5c",
            "74d259a96f534c88a1cecbdc647be2d6",
            "62ae69db2d1d49049a86fcaf46090566",
            "fb6148cff0fa4ec39e4882c53dfb0b62",
            "532db4e865214b379367afef994002f2"
          ]
        },
        "id": "5GIk4SI6lRoC",
        "outputId": "36b0211f-d11d-4df3-d4c5-320bc8721de6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/944 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "876c992719644e338e11f3362cf6cb5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001-297892d5d4e8a0(…):   0%|          | 0.00/36.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09cae9c3e9d14cf5a4420b226a21c394"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d03c09063d648f494c3c4f8ad0a16ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['output', 'input', 'instruction'],\n",
            "        num_rows: 52002\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example(example):\n",
        "    instruction = example.get(\"instruction\", \"\")\n",
        "    input_text = example.get(\"input\", \"\")\n",
        "    output_text = example.get(\"output\", \"\")\n",
        "    return {\n",
        "        \"text\": f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{output_text}\\n\\n### Disclaimer:\\nThis is educational only — consult a qualified clinician.\"\n",
        "    }\n",
        "\n",
        "formatted_dataset = dataset.map(format_example)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f157ced57b8b4c6ba270227ddf3246a6",
            "f5a48674f53b44babffac7a9f896daf0",
            "4adf065603f84ab9957a806768ce3043",
            "c49c2b6cd6ad427aa82b4ad5044515c7",
            "60e833969bc1403e94438fb53bc6111a",
            "9b754b5ecd284f45b7685b33e3e0f744",
            "ea26299cb664438bb52b4ce8ec4ffcff",
            "c40213ed6abc4a0cb0d92ccd6f424d41",
            "260472637a224a138d2b07b8101424ef",
            "54ff1261d8ef463d91d80de8001702fe",
            "8665077b009f42cfbc2ca930139ce7c6"
          ]
        },
        "id": "WWtobH28lgH0",
        "outputId": "9370e6da-524f-466e-c25e-8d12cdae62ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/52002 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f157ced57b8b4c6ba270227ddf3246a6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = formatted_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "val_test_split = split_dataset[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "train_data = split_dataset[\"train\"]\n",
        "val_data = val_test_split[\"train\"]\n",
        "test_data = val_test_split[\"test\"]\n"
      ],
      "metadata": {
        "id": "lB7JzsRYljTu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes transformers accelerate peft\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch\n",
        "\n",
        "# Load model name\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "# 8-bit quantization config (saves GPU memory)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    llm_int8_threshold=6.0\n",
        ")\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"✅ Model and tokenizer loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a0c4ac715eae438aa3859410a0cf2d67",
            "a029af4e42ef48488c25f8d4d9144d71",
            "6f599d6698ac4caca14eff8e88c25b3a",
            "52b2c66e4f1f4c069628cedf54fc9306",
            "05d1d78ceaec499fb6f769eb715ffeec",
            "14865db2b5d54ff7b4c1518f9987ca58",
            "77e97f8c897f4dd7a2a6de43f5850e71",
            "5062ac0dabef4a43b2d25e3ed8df56a5",
            "eeb08ffe39d549d98fb80231a645af7d",
            "ddb20940061546a0914db10dbcfe97b1",
            "b25aefac7b8a465d831c33b6c5e59e1a",
            "eba27e707fc64304b7b0bdabfc3b5c03",
            "ed2bcba5330a40e1b99890beac7a68ea",
            "f464b5ab94db4bc08f1392ab69f5ecdb",
            "fac9e1f9724640ef87fd6ba0d2e47031",
            "3a8dea62319845998756adc944ebb27d",
            "a182dccdfdc14199b72e5d6e7c848afe",
            "3d308a1dcec24869aa8a699d383ebc74",
            "7b2e66e2cddc445db117346675ba38a9",
            "15910eb404414f2692d6f2cff51cc162",
            "303b8386b3594095b4e2be38cfdceeba",
            "d2c6ac2cdd5b4db496130bcda967f01c",
            "7b35f97df8f34faf9a89483391c68866",
            "61ffc8e704804243b2ca1288b8fd9a01",
            "e37f82a5fcf641e08f5ad04164af3f07",
            "4372b23aaa264f309a3302baa83726ac",
            "dc5625dd1b884369bcde1ec9eecb7e9c",
            "91e7df26e48b455c994ac500130fe0a9",
            "acd1a8b91af04291bd41b5769d5817a1",
            "98e3347dbb6245dcbf73cf077234900b",
            "40964daf2c0d4a8e904375790eee9724",
            "3cb1bfd857e34db58ff3bf151314eb78",
            "8254dfdead944f07b8b92ce154240674",
            "46d31e900b3046dd9bac4362e3a81a7f",
            "9fd719891dd1428f9659b33c94815903",
            "785610288d034713a22f87ed1c667512",
            "dbaaef50339c44ee8e74b78a6dd52663",
            "ff5462aab84d4a0299d636760d452ed6",
            "12fe08ce74ac4df38e9a53dd52566ad3",
            "4afd0ce3fb3e4c63be6dc892debe1886",
            "905c0c69350f4cf78d1392ad25c81aea",
            "f350e68472124fc18faedf16557d889f",
            "56283da95c4e4891b4184920a7665690",
            "4c8029eac7b84b69b598601e81b808a9",
            "cc527642744448b0a2f9e25f327cc598",
            "804bd916d63a4bec9b008ca4721a6774",
            "07ad26f83dcd47028d5c2f900bb0f878",
            "1c2aeed512e745f686edb8c5912caf41",
            "0f3c702d226a437c8c024ce194f4e044",
            "d1630371cda44d63937165932e8518cd",
            "ca114716f60a4fe29d3b50336a433cf7",
            "c854bc8537114544b930ef73cf924429",
            "8e51c1fee4834594aa9a7d5406868724",
            "507582881f6d44619deef85a9dd61ba3",
            "e77e8004a11d413fb4dfbf2a3ed16418",
            "63a4d11126f541238e992f58325495f6",
            "0b454e92e4c645d89a9fce8962854113",
            "3a86daefdf5643949f1ca7d61ae07276",
            "0eb0d8df518a43df84a13005831e0ad4",
            "97292e1e47934a34a1d7080d89fc5fe3",
            "4c5e2dc39fc14beda854f88f4d3fd310",
            "25d33782f6094294801244014d2ae4e5",
            "1f5aed8cd150432597f6bad8ad51dd7d",
            "bdf8fcd9990641b6bf1a69c1ebebe31b",
            "f17c4d0f6e8d449ab25270e07dc3aed8",
            "ed2ebb60abf54608aefc186934be938f",
            "28d6ca6c67eb4075bc2caf8af865bb99",
            "81b40c0bea9b421c9702f67550aaf408",
            "8c31fdbc119d46d79aa6c7a111d16144",
            "05d505cb47a04b43a97724d8e39c23fe",
            "3fdeac7daa78438ca1e67527cf80091b",
            "6e5933190b8f4bebac5522eae4f5fe98",
            "765bd4ab4b20488e98167d2ae263cc08",
            "8ef3aa191e674ff28919cd586569cd26",
            "f72b260712914ec7b288b16ea55e6212",
            "c204392c082a418db4724ad0655583b2",
            "30af839ac6e740fba2d3da316472911f"
          ]
        },
        "id": "3a7Fn-eOlmqL",
        "outputId": "12ba3c06-6b9d-4811-f65a-fd0561cd8700"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Downloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "Successfully installed transformers-4.57.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0c4ac715eae438aa3859410a0cf2d67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eba27e707fc64304b7b0bdabfc3b5c03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b35f97df8f34faf9a89483391c68866"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46d31e900b3046dd9bac4362e3a81a7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc527642744448b0a2f9e25f327cc598"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63a4d11126f541238e992f58325495f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28d6ca6c67eb4075bc2caf8af865bb99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and tokenizer loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# Define LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=8,                      # rank\n",
        "    lora_alpha=16,            # scaling factor\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],  # layers to adapt\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "# Apply LoRA to the base model\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Print trainable parameters\n",
        "lora_model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP9MBTValpmw",
        "outputId": "14b04f8d-2d08-4049-9337-07d2bd0b25f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.1023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "tokenized_train = train_data.map(tokenize_function, batched=True)\n",
        "tokenized_val = val_data.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d20cabf025b747f58262a3e41149231c",
            "84dd431dd3c046f4914d623e1c37e475",
            "da831a5545224128bf9af1d51191bbf7",
            "044db5731ace4e988e3ce96615319d78",
            "b9f2f99b355d42f692af4bfb29cdeb34",
            "22b1fdf1a7674bf8bc4f760ad01812ab",
            "dbf712f23f2f45eaa31758e68fbd1883",
            "7a69ece01e074b7db728c6520c3fb35d",
            "82db03f4ea7e4590a2e316908c519f0f",
            "af86d08c9eb34182b706acf0cf930199",
            "35d012b244bd429ba4ffbd7c1bb88e08",
            "bd420cd86f294c20afc1833ce979eb45",
            "26adc78c7714494fbab11216cd2b4f52",
            "51dd415ddc714e13af1e4c101a281304",
            "2af01c52f9224e65b1c555466cb87747",
            "bb90dd5b288e457ca10a18f7b571b753",
            "0fb93973e73747b297969907fa3b6201",
            "2934db12aaab4ab0a409421e66ef1690",
            "5a05a0e6ecc34ffba3e89a0c900cf7a4",
            "0df919facadc4eef96677d7f2c537d6a",
            "a1c9403250b1433695828d182a04f39d",
            "a1d89f57427d48818f32c7575f069c4b"
          ]
        },
        "id": "-Hja4HUhlwx8",
        "outputId": "20a3784d-764c-486f-ce02-b20588df695a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/46801 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d20cabf025b747f58262a3e41149231c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd420cd86f294c20afc1833ce979eb45"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"lavita/AlpaCare-MedInstruct-52k\")\n",
        "\n",
        "# Format dataset text\n",
        "def format_example(example):\n",
        "    instruction = example.get(\"instruction\", \"\")\n",
        "    input_text = example.get(\"input\", \"\")\n",
        "    output_text = example.get(\"output\", \"\")\n",
        "    return {\n",
        "        \"text\": f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{output_text}\\n\\n### Disclaimer:\\nThis is educational only — consult a qualified clinician.\"\n",
        "    }\n",
        "\n",
        "formatted_dataset = dataset.map(format_example)\n",
        "\n",
        "# Split train/val/test\n",
        "split_dataset = formatted_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "val_test_split = split_dataset[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "train_data = split_dataset[\"train\"]\n",
        "val_data = val_test_split[\"train\"]\n",
        "test_data = val_test_split[\"test\"]\n",
        "\n",
        "# Tokenize\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "tokenized_train = train_data.map(tokenize_function, batched=True)\n",
        "tokenized_val = val_data.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "0989239817e64837aea999d1864c3bdf",
            "f519e35c6e2e4775a36bbb66afdeae22",
            "e7c854c971de4ee9bdaa8e87c5b1dc2e",
            "dc0dcfa5a2fb4e0193ff9eaf97a4c398",
            "f5a133587a8340b58430018487f8f727",
            "c6764a86f6a14df983857579cb5e46ef",
            "aeab46fef02f42cf931013cad451a596",
            "1d052df9227941e186f514b18c355260",
            "e9b1ef96463f4716b4b0c46208f41e64",
            "97712344f58c4f8ca6619c186ff09448",
            "e048fcadd5a44218a97a9e878a1dd587",
            "f227f9b486034155a18f37d09786774f",
            "29e4ddf0ab864c07a87a51bcfc66b68c",
            "350811dbead74d3586662436045a20ba",
            "a26f8611bc7f4abdb4430a59c55c77b3",
            "3abf5e113c4a4210820444fc264f62d7",
            "65f3ca29064246d494adbd60873d5e89",
            "c02fd6b7225d43bbb0603ca645e9fbcf",
            "5cce48bae6c548abb3cbd6c0ad260c16",
            "a8f957c6567041d38a8bee3dbbe1cc0c",
            "bd031969192c48d08f457e8a480baca9",
            "33df5aa81c5d40ba8949e169a1d86878",
            "c207befcb1654fe0bb3e0a5eb469ac39",
            "3acd796758f248bab4d99934e11b80ce",
            "8f037e0a8e974fbdbb6ea437da19083b",
            "e238a5ab318a453aa3335c1fbabc67ee",
            "9edebe55cc5942fc840fceeac8345b4f",
            "a49e2cf1b8714e34b787dc4404de7564",
            "d62e8ab1e6b947c3b4340fd7ebcadf51",
            "d28f24967d4a4c6b88b1f15c6b9d76a2",
            "230199cf8da24449b572f04d5344a927",
            "6ae7e2e6657543a38bebc5f40654e158",
            "adaf3bd93e9444b09a737d61b4674c92"
          ]
        },
        "id": "FxWe544YmFOX",
        "outputId": "e96b2088-d32c-47e7-b7c1-23cc96189836"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/52002 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0989239817e64837aea999d1864c3bdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/46801 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f227f9b486034155a18f37d09786774f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c207befcb1654fe0bb3e0a5eb469ac39"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example(example):\n",
        "    instruction = example.get(\"instruction\", \"\")\n",
        "    input_text = example.get(\"input\", \"\")\n",
        "    output_text = example.get(\"output\", \"\")\n",
        "    return {\n",
        "        \"text\": f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{output_text}\\n\\n### Disclaimer:\\nThis is educational only — consult a qualified clinician.\"\n",
        "    }\n",
        "\n",
        "formatted_dataset = dataset.map(format_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f12c0be4ab3c47978cb0473a1780b94a",
            "96bedcd46402497e911d84dc758768b7",
            "713ebd35299e4bd4a902bcdfc5584889",
            "0c4ef1dc1fd04b31afd716cee13e6145",
            "a25ce6aad29a4325a99519d35b09c3e6",
            "366d37dae94f42988059cce0b6b0a3fc",
            "3e3a4b576d9b4e81be29268a7ebf115e",
            "406ede9258644af9ada0d069e680d5ee",
            "0fe372974176403e8741b310c05320cf",
            "0e71f4cb2cb44bb7a74304cc31d95561",
            "4f9b2b182959454aa5af244e1dd39588"
          ]
        },
        "id": "AjiZi3WTmTNF",
        "outputId": "925abd41-d3bb-404f-97db-f2673a058e8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/52002 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f12c0be4ab3c47978cb0473a1780b94a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = formatted_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "val_test_split = split_dataset[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "train_data = split_dataset[\"train\"]\n",
        "val_data = val_test_split[\"train\"]\n",
        "test_data = val_test_split[\"test\"]"
      ],
      "metadata": {
        "id": "D0mT4ekVmhab"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "# disable cache (recommended when fine-tuning with PEFT/LoRA)\n",
        "lora_model.config.use_cache = False\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora-medical-model\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=50,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=2,   # safe to keep\n",
        "    # <-- intentionally not using evaluation_strategy or save_strategy\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()\n",
        "\n",
        "# Run evaluation manually after training\n",
        "metrics = trainer.evaluate(eval_dataset=tokenized_val)\n",
        "print(\"Evaluation metrics:\", metrics)\n",
        "\n",
        "# Save only LoRA adapter + tokenizer (do not attempt to save the full quantized base model)\n",
        "lora_model.save_pretrained(\"./lora_medical_adapter\")\n",
        "tokenizer.save_pretrained(\"./lora_medical_adapter\")\n",
        "\n",
        "print(\"✅ Training complete — LoRA adapter saved at ./lora_medical_adapter\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wu32GFvKmh6t",
        "outputId": "f34e2daa-231a-4dc4-96f6-6e0ac89162ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2507' max='2926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2507/2926 2:11:41 < 22:01, 0.32 it/s, Epoch 0.86/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.203100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.043800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.998700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.995800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.995700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.985400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.987500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.969400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.989800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.969400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.978700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.976200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.964700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.968700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.964500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.968200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.969600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.962100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.965700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.967600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.966700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.964100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.966600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.966700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.966900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.962800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.959800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.964500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.970300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.956100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.955700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.959500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.955500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.954600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.958400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.956500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.954200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.956000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.944300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.965100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.940800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.963500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.960800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.959800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.951800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2926' max='2926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2926/2926 2:33:42, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.203100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.043800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.998700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.995800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.995700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.985400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.987500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.969400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.989800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.969400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.978700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.976200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.964700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.968700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.964500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.968200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.969600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.962100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.965700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.967600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.966700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.964100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.966600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.966700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.966900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.962800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.959800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.964500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.970300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.956100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.955700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.959500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.955500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.954600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.958400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.956500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.954200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.956000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.944300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.965100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.940800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.963500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.960800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.959800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.951800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.964400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.958400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.955200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.963600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.962400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.949400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.953200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.959300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='650' max='650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [650/650 03:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics: {'eval_loss': 0.958119809627533, 'eval_runtime': 232.6076, 'eval_samples_per_second': 11.178, 'eval_steps_per_second': 2.794, 'epoch': 1.0}\n",
            "✅ Training complete — LoRA adapter saved at ./lora_medical_adapter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load base model + LoRA adapter\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "instruct_model = PeftModel.from_pretrained(base_model, \"./lora_medical_adapter\")\n",
        "instruct_model.eval()\n",
        "\n",
        "# Reload tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./lora_medical_adapter\")\n",
        "\n",
        "# Create text-generation pipeline\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=instruct_model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=200,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "# 🔍 Test prompt\n",
        "prompt = \"\"\"### Instruction:\n",
        "Explain the importance of staying hydrated during fever.\n",
        "\n",
        "### Input:\n",
        "A 10-year-old child has mild fever and reduced appetite.\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "output = generator(prompt)[0]['generated_text']\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD1GSRbfmlMO",
        "outputId": "16be40d2-35c4-4e2a-fdb2-8b61cf970440"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "Explain the importance of staying hydrated during fever.\n",
            "\n",
            "### Input:\n",
            "A 10-year-old child has mild fever and reduced appetite.\n",
            "\n",
            "### Response:\n",
            "Staying hydrated during a fever is crucial for preventing complications and ensuring proper health. Here are the reasons why:\n",
            "\n",
            "1. Protects against infections: Dehydration can make it difficult for the body to fight off infections. Drinking plenty of fluids helps to replenish depleted fluids, preventing dehydration and reducing the risk of infections.\n",
            "\n",
            "2. Promotes digestion and nutrient absorption: Drinking enough fluids helps to lubricate the stomach and improve digestion. This ensures that nutrients are properly absorbed and helps to promote overall health.\n",
            "\n",
            "3. Helps regulate body temperature: Dehydration can lead to a higher body temperature, which can be uncomfortable and potentially dangerous. Drinking enough fluids helps to regulate body temperature, which is important for overall\n"
          ]
        }
      ]
    }
  ]
}